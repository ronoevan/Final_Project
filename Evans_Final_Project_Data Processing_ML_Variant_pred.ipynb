{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final_Project: Prospects of Machine learning Approaches in predicting new variants or new mutations in hCoV-2 spike sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "## multiple outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder# example of a one hot encoding\n",
    "from numpy import asarray# example of a one hot encoding\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "pd.options.display.max_rows = 50\n",
    "## Install xlrd package to load Excel files\n",
    "# conda install openpyxl\n",
    "## conda install xlrd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To  predict a new Amino Acid sequence/or its class (variant)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('new_for_model_testing.csv')\n",
    "test= list(test['spike_aa'])[4]#for predicting \n",
    "#test#\n",
    "\n",
    "modelling_set = pd.read_csv('modelling_set1.csv')#for trainingset\n",
    "\n",
    "sequence=list(modelling_set['spike_aa'])#feature column\n",
    "label=list(modelling_set['variant'])#variants as labels\n",
    "\n",
    "#modelling_set = modelling_set.drop_duplicates(subset=['spike_aa']).reset_index()\n",
    "#modelling_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.info()\n",
    "test=pd.DataFrame(test[['spike_aa','variant']][3:17]).reset_index()#variant\n",
    "test\n",
    "test.to_csv('test_unseen_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelling_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelling_set=modelling_set[['orf1a_aa', 'variant']]\n",
    "modelling_set\n",
    "modelling_set.to_csv(\"modelling_set.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test=pd.DataFrame(test)\n",
    "\n",
    "test.to_csv(\"test_sequence.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelling_set=modelling_set[['orf1a_aa', 'variant']]\n",
    "modelling_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define: \n",
    "**1. Amino acids sequences**\n",
    "\n",
    "**2. Characters present in the strings 'sequence'** and\n",
    "\n",
    "**3. Function for the one-hot encode array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chatGTP on 18:00 11.05.2023. It kills the python kernel. Too expensive for my computer\n",
    "import numpy as np\n",
    "\n",
    "# Define a list of amino acids in alphabetical order\n",
    "amino_acids = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y', '*']\n",
    "\n",
    "# Define a function to convert a string of amino acids to a one-hot encoded array\n",
    "def one_hot_encode(sequence, amino_acids):\n",
    "    # Initialize an array of zeros with dimensions (length of sequence, number of amino acids)\n",
    "    encoded = np.zeros((len(sequence), len(amino_acids)))\n",
    "    # Loop over each amino acid in the sequence\n",
    "    for i, amino_acid in enumerate(sequence):\n",
    "        # Set the corresponding position in the encoded array to 1\n",
    "        encoded[i, amino_acids.index(amino_acid)] = 1\n",
    "    return encoded\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define: \n",
    "**1. Training set of amino acid sequences** and \n",
    "\n",
    "**2. The corresponding labels (variants)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a training set of amino acid sequences and their corresponding labels\n",
    "#training_sequences = ['ACDEFGHIKLMNPQRSTVWY', 'AAAAAAACCCCCGGGGGTTTTT', 'ACDEFGHIKLMNPQRSTVWY', 'ACDEFGHIKLMNPQRSTVWY']\n",
    "#training_labels = ['protein', 'nucleotide', 'protein', 'protein']\n",
    "training_sequences = sequence#df['spike_aa']\n",
    "training_labels = label#df['variant']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode the training sequences as one-hot encoded arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode the training sequences as one-hot encoded arrays\n",
    "encoded_training_sequences = np.array([one_hot_encode(sequence, amino_acids) for sequence in training_sequences])\n",
    "\n",
    "# Define a simple neural network with one hidden layer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "#model = Sequential()#binary class\n",
    "model = tf.keras.models.Sequential()#For multi-class\n",
    "model.add(Dense(units=10, input_dim=len(amino_acids), activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model with multi-class cross-entropy loss and Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])#binary\n",
    "\n",
    "# Compile the model for multi-class cross-entropy loss function used for classification problems.\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model on the encoded training sequences and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the encoded training sequences and labels\n",
    "model.fit(encoded_training_sequences, np.array(training_labels)=='protein', epochs=100, batch_size=1)\n",
    "\n",
    "# Define a test sequence and encode it as a one-hot encoded array\n",
    "test_sequence = test['spike_aa']#'ACDEFGHIKLMNPQRSTVWY'\n",
    "encoded_test_sequence = one_hot_encode(test_sequence, amino_acids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the label of the test sequence using the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the label of the test sequence using the trained model\n",
    "prediction = model.predict(np.array([encoded_test_sequence]))\n",
    "\n",
    "# Print the predicted label\n",
    "if prediction > 0.5:\n",
    "    print('This is a known variant.')\n",
    "else:\n",
    "    print('This is likely to be a new variant.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To  predict a new Amino Acid sequence/or its class (variant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "## multiple outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder# example of a one hot encoding\n",
    "from numpy import asarray# example of a one hot encoding\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "pd.options.display.max_rows = 50\n",
    "## Install xlrd package to load Excel files\n",
    "# conda install openpyxl\n",
    "## conda install xlrd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('new_for_model_testing.csv')\n",
    "\n",
    "\n",
    "test= list(test['spike_aa'])[4]#for predicting \n",
    "#test#\n",
    "#test= test['spike_aa']\n",
    "#modelling_set = pd.read_csv('modelling_set1.csv')#for trainingset\n",
    "modelling_set = pd.read_csv('combined3melted_orf1a_s.csv')\n",
    "\n",
    "#Using orf1a\n",
    "#sequence=list(modelling_set['orf1a_aa'])#feature column\n",
    "#label=list(modelling_set['variant'])#variants as labels\n",
    "\n",
    "#modelling_set = modelling_set.drop_duplicates(subset=['spike_aa']).reset_index()\n",
    "#modelling_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['orf1a_cdna_width', 'orf1a_aa', 'orf1a_aa_width', 'spike_cdna_width',\n",
       "       'spike_aa', 'spike_aa_width', 'B.1.1.7_Alpha', 'B.1.351_Beta',\n",
       "       'B.1.1.248_P1_Gamma', 'P.2_Zeta', 'B.1.617.1_Kappa', 'B.1.617.2_Delta',\n",
       "       'B.1.617.2_Delta_Plus', 'B.1.617.3', 'B.1.427_Epsilon',\n",
       "       'B.1.429_Epsilon', 'B.1.526_Iota', 'B.1.525_Eta', 'P.3_Theta',\n",
       "       'B.1.1.529_Omicron', 'B.1.1.529.1_Omicron', 'Delta_lineage',\n",
       "       'Omicron_lineage', 'Other', 'variant', 'duplicated'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelling_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spike_aa</th>\n",
       "      <th>spike_aa_width</th>\n",
       "      <th>variant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>1270</td>\n",
       "      <td>B.1.1.7_Alpha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>1270</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>1270</td>\n",
       "      <td>B.1.1.7_Alpha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>1270</td>\n",
       "      <td>B.1.1.7_Alpha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>1270</td>\n",
       "      <td>B.1.1.7_Alpha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12601</th>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>1270</td>\n",
       "      <td>B.1.1.529_Omicron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12602</th>\n",
       "      <td>MFVFLVLLPLVSSQCVNLITRTQSYTNSFTRGVYYPDKVFRSSVLH...</td>\n",
       "      <td>1267</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12603</th>\n",
       "      <td>MFVFLVLLPLVSIQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>1270</td>\n",
       "      <td>B.1.1.529_Omicron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12604</th>\n",
       "      <td>MFVFLVLLPLVFSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>1270</td>\n",
       "      <td>B.1.1.529_Omicron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12605</th>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>1270</td>\n",
       "      <td>B.1.1.529_Omicron</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12606 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                spike_aa  spike_aa_width  \\\n",
       "0      MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...            1270   \n",
       "1      MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...            1270   \n",
       "2      MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...            1270   \n",
       "3      MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...            1270   \n",
       "4      MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...            1270   \n",
       "...                                                  ...             ...   \n",
       "12601  MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...            1270   \n",
       "12602  MFVFLVLLPLVSSQCVNLITRTQSYTNSFTRGVYYPDKVFRSSVLH...            1267   \n",
       "12603  MFVFLVLLPLVSIQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...            1270   \n",
       "12604  MFVFLVLLPLVFSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...            1270   \n",
       "12605  MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...            1270   \n",
       "\n",
       "                 variant  \n",
       "0          B.1.1.7_Alpha  \n",
       "1                  Other  \n",
       "2          B.1.1.7_Alpha  \n",
       "3          B.1.1.7_Alpha  \n",
       "4          B.1.1.7_Alpha  \n",
       "...                  ...  \n",
       "12601  B.1.1.529_Omicron  \n",
       "12602              Other  \n",
       "12603  B.1.1.529_Omicron  \n",
       "12604  B.1.1.529_Omicron  \n",
       "12605  B.1.1.529_Omicron  \n",
       "\n",
       "[12606 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelling_set =modelling_set.drop_duplicates(subset=['spike_aa']).reset_index()\n",
    "modelling_set =modelling_set[['spike_aa','spike_aa_width', 'variant']]\n",
    "modelling_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#modelling_set.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define: \n",
    "**1. Amino acids sequences**\n",
    "\n",
    "**2. Characters present in the strings 'sequence'** and\n",
    "\n",
    "**3. Function for the one-hot encode array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.52418715305313 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "#\n",
    "#Using spike\n",
    "sequence=list(modelling_set['spike_aa'])#feature column\n",
    "label=list(modelling_set['variant'])#variants as labels\n",
    "#\n",
    "#define amino acids possibilities found in the sequence\n",
    "amino_acids = 'ACDEFGHIKLMNPQRSTVWY*'\n",
    "\n",
    "# Define the amino acid sequence data\n",
    "X=np.array(sequence)\n",
    "\n",
    "# Define the corresponding labels (e.g., 0 = non-functional, 1 = functional)\n",
    "y= label\n",
    "\n",
    "max_sequence_length=modelling_set['spike_aa_width'].max()\n",
    "num_samples =len(modelling_set)\n",
    "# Convert amino acid sequences to numerical vectors\n",
    "aa_to_index = {aa: i for i, aa in enumerate(amino_acids)}\n",
    "X_encoded = []\n",
    "for i in range(num_samples):\n",
    "    encoded_seq = [aa_to_index[aa] for aa in X[i]]\n",
    "    padded_seq = np.pad(encoded_seq, (0, max_sequence_length - len(encoded_seq)))\n",
    "    X_encoded.append(padded_seq)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Random Forest Classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', acc*100,\"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the amino acid sequence data\n",
    "sequences = sequence#np.array(sequence)#sequence\n",
    "\n",
    "\n",
    "# Define the corresponding labels (e.g., 0 = non-functional, 1 = functional)\n",
    "labels = label\n",
    "\n",
    "# Define the 20 amino acids and the stop codon *\n",
    "#amino_acids = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y', '*']\n",
    "amino_acids = 'ACDEFGHIKLMNPQRSTVWY*'\n",
    "# Convert the amino acid sequences to numerical features using one-hot encoding\n",
    "#features = []\n",
    "#for seq in sequences:\n",
    " #   feature = []\n",
    "  #  for aa in seq:\n",
    "   #     if aa not in amino_acids:\n",
    "    #        raise ValueError('Invalid amino acid character: %s' % aa)\n",
    "     #   aa_idx = amino_acids.index(aa)\n",
    "      #  aa_feature = [int(i == aa_idx) for i in range(len(amino_acids))]\n",
    "       # feature.extend(aa_feature)\n",
    "   # features.append(feature)\n",
    "    #features.append(np.array(feature))\n",
    "    \n",
    "aa_to_index = {aa: i for i, aa in enumerate(amino_acids)}\n",
    "X_encoded = []\n",
    "for i in range(num_samples):\n",
    "    encoded_seq = [aa_to_index[aa] for aa in X[i]]\n",
    "    padded_seq = np.pad(encoded_seq, (0, max_sequence_length - len(encoded_seq)))\n",
    "    X_encoded.append(padded_seq)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "labels = label\n",
    "#X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "#X_train = np.array(X_train).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode the training sequences as one-hot encoded arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a random forest classifier on the training data\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the labels of the testing data using the trained classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels of the testing data using the trained classifier\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the accuracy of the classifier on the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  4, 17, ...,  0,  0,  0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_train)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "  B.1.1.248_P1_Gamma       0.80      1.00      0.89         8\n",
      "   B.1.1.529_Omicron       0.99      0.99      0.99        78\n",
      "       B.1.1.7_Alpha       1.00      1.00      1.00       412\n",
      "     B.1.427_Epsilon       1.00      1.00      1.00        32\n",
      "     B.1.617.2_Delta       1.00      1.00      1.00      1232\n",
      "B.1.617.2_Delta_Plus       1.00      1.00      1.00         1\n",
      "       Delta_lineage       1.00      0.92      0.96        50\n",
      "     Omicron_lineage       1.00      0.96      0.98        24\n",
      "               Other       0.99      1.00      0.99       677\n",
      "            P.2_Zeta       0.83      0.62      0.71         8\n",
      "\n",
      "            accuracy                           1.00      2522\n",
      "           macro avg       0.96      0.95      0.95      2522\n",
      "        weighted avg       1.00      1.00      1.00      2522\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report( y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                      precision    recall  f1-score   support\\n\\n  B.1.1.248_P1_Gamma       0.80      1.00      0.89         8\\n   B.1.1.529_Omicron       0.99      0.99      0.99        78\\n       B.1.1.7_Alpha       1.00      1.00      1.00       412\\n     B.1.427_Epsilon       1.00      1.00      1.00        32\\n     B.1.617.2_Delta       1.00      1.00      1.00      1232\\nB.1.617.2_Delta_Plus       1.00      1.00      1.00         1\\n       Delta_lineage       1.00      0.92      0.96        50\\n     Omicron_lineage       1.00      0.96      0.98        24\\n               Other       0.99      1.00      0.99       677\\n            P.2_Zeta       0.83      0.62      0.71         8\\n\\n            accuracy                           1.00      2522\\n           macro avg       0.96      0.95      0.95      2522\\n        weighted avg       1.00      1.00      1.00      2522\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report( y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.52418715305313 %\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the accuracy of the classifier on the testing data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.52418715305313 %\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the accuracy of the classifier on the testing data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy*100,'%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.52418715305313 %\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the accuracy of the classifier on the testing data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy*100,'%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.52418715305313 %\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the accuracy of the classifier on the testing data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy*100,'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.52418715305313 %\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the accuracy of the classifier on the testing data\n",
    "accuracy = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "print(\"Accuracy:\", accuracy*100,'%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.52744944998335 %\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the accuracy of the classifier on the testing data\n",
    "accuracy = precision_score(y_test, y_pred, average=\"weighted\")\n",
    "print(\"Accuracy:\", accuracy*100,'%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting unseen Amino Acid Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: B.1.1.7_Alpha\n"
     ]
    }
   ],
   "source": [
    "#test = pd.read_csv('new_for_model_testing2.csv')\n",
    "test = pd.read_csv('new_for_model_testing.csv')\n",
    "new_sequence= test['spike_aa'][4]\n",
    "#new_sequence= list(test['spike_aa'])[700]\n",
    "\n",
    "max_sequence_length=modelling_set['spike_aa_width'].max()\n",
    "# Convert the new sequence to a numerical vector using the same encoding scheme as the training data\n",
    "encoded_seq = [aa_to_index[aa] for aa in new_sequence]\n",
    "padded_seq = np.pad(encoded_seq, (0, max_sequence_length - len(encoded_seq)))\n",
    "X_new = [padded_seq]\n",
    "\n",
    "# Use the trained classifier to predict the class of the new sequence\n",
    "y_new = clf.predict(X_new)\n",
    "print('Predicted class:', y_new[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest to Predict the probability of having new mutations in a new protein sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of each mutation class: [  0.   0. 100.   0.   0.   0.   0.   0.   0.   0.   0.] %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define the training data\n",
    "X_train = np.array(sequence)\n",
    "y_train = y = label\n",
    "\n",
    "# Define the encoding scheme\n",
    "aa_list = 'ACDEFGHIKLMNPQRSTVWY*'\n",
    "aa_to_index = {aa: i for i, aa in enumerate(aa_list)}\n",
    "\n",
    "# Encode the training data\n",
    "max_sequence_length = max([len(seq) for seq in X_train])\n",
    "X_encoded = [[aa_to_index[aa] for aa in seq] for seq in X_train]\n",
    "X_padded = [np.pad(seq, (0, max_sequence_length - len(seq))) for seq in X_encoded]\n",
    "\n",
    "# Train the classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_padded, y_train)\n",
    "\n",
    "# Define a new sequence with a mutation and encode it\n",
    "new_sequence = list(test['spike_aa'])[4]#'MENLC*MNVVRKF*KC'\n",
    "new_encoded = [aa_to_index[aa] for aa in new_sequence]\n",
    "new_padded = np.pad(new_encoded, (0, max_sequence_length - len(new_encoded)))\n",
    "\n",
    "# Use the classifier to predict the probability of having new mutations\n",
    "y_pred_proba = clf.predict_proba([new_padded])\n",
    "print('Probability of each mutation class:', y_pred_proba[0]*100,'%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('new_for_model_testing.csv')\n",
    "\n",
    "\n",
    "#test= list(test['spike_aa'])[4]#for predicting \n",
    "#test#\n",
    "#test= test['spike_aa']\n",
    "#modelling_set = pd.read_csv('modelling_set1.csv')#for trainingset\n",
    "modelling_set = pd.read_csv('trainingset.csv')\n",
    "#Using spike\n",
    "sequence=list(modelling_set['spike_aa'])#feature column\n",
    "label=list(modelling_set['variant'])#variants as labels\n",
    "\n",
    "#\n",
    "#Using orf1a\n",
    "#sequence=list(modelling_set['orf1a_aa'])#feature column\n",
    "#label=list(modelling_set['variant'])#variants as labels\n",
    "\n",
    "#modelling_set = modelling_set.drop_duplicates(subset=['spike_aa']).reset_index()\n",
    "#modelling_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelling_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#modelling_set =modelling_set.drop_duplicates(subset=['spike_aa'])\n",
    "#modelling_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Amino acid\n",
    "amino_acids = 'ACDEFGHIKLMNPQRSTVWY*'\n",
    "\n",
    "X = np.array(sequence)\n",
    "y = label\n",
    "\n",
    "# Convert amino acid sequences to numerical vectors\n",
    "aa_to_index = {aa: i for i, aa in enumerate(amino_acids)}\n",
    "X_encoded = []\n",
    "for i in range(len(sequence)):\n",
    "    encoded_seq = [aa_to_index[aa] for aa in X[i]]\n",
    "    padded_seq = np.pad(encoded_seq, (0, modelling_set['spike_aa_width'].max() - len(encoded_seq)))\n",
    "    X_encoded.append(padded_seq)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Random Forest Classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', acc*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = pd.read_csv('new_for_model_testing2.csv')\n",
    "test = pd.read_csv('new_for_model_testing.csv')\n",
    "\n",
    "#new_sequence= test['spike_aa']#[2]\n",
    "new_sequence= list(test['spike_aa'])[13]\n",
    "\n",
    "\n",
    "# Convert the new sequence to a numerical vector using the same encoding scheme as the training data\n",
    "encoded_seq = [aa_to_index[aa] for aa in new_sequence]\n",
    "padded_seq = np.pad(encoded_seq, (0, modelling_set['spike_aa_width'].max() - len(encoded_seq)))\n",
    "X_new = [padded_seq]\n",
    "\n",
    "# Use the trained classifier to predict the class of the new sequence\n",
    "y_new = clf.predict(X_new)\n",
    "print('Predicted class:', y_new[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###With cDNA in spike gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('new_for_model_testing.csv')\n",
    "\n",
    "\n",
    "test= list(test['spike_cdna'])[4]#for predicting \n",
    "#test#\n",
    "#test= test['spike_aa']\n",
    "#modelling_set = pd.read_csv('modelling_set1.csv')#for trainingset\n",
    "modelling_set = pd.read_csv('trainingset.csv')\n",
    "#Using spike\n",
    "sequence=list(modelling_set['spike_cdna'])#feature column\n",
    "label=list(modelling_set['variant'])#variants as labels\n",
    "\n",
    "#spike_cdna\n",
    "#Using orf1a\n",
    "#sequence=list(modelling_set['orf1a_aa'])#feature column\n",
    "#label=list(modelling_set['variant'])#variants as labels\n",
    "\n",
    "#modelling_set = modelling_set.drop_duplicates(subset=['spike_aa']).reset_index()\n",
    "#modelling_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Amino acid\n",
    "cdna_seqs = 'ATCG'\n",
    "\n",
    "X = np.array(sequence)\n",
    "y = label\n",
    "\n",
    "# Convert amino acid sequences to numerical vectors\n",
    "cdna_to_index = {cdna: i for i, cdna in enumerate(cdna_seqs)}\n",
    "X_encoded = []\n",
    "for i in range(len(sequence)):\n",
    "    encoded_seq = [cdna_to_index[cdna] for cdna in X[i]]\n",
    "    padded_seq = np.pad(encoded_seq, (0, modelling_set['spike_cdna_width'].max() - len(encoded_seq)))\n",
    "    X_encoded.append(padded_seq)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Random Forest Classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', acc*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('new_for_model_testing.csv')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_sequence= test['spike_aa']#[2]\n",
    "new_sequence= list(test['spike_aa'])[31]\n",
    "\n",
    "\n",
    "# Convert the new sequence to a numerical vector using the same encoding scheme as the training data\n",
    "encoded_seq = [aa_to_index[aa] for aa in new_sequence]\n",
    "padded_seq = np.pad(encoded_seq, (0, modelling_set['spike_cdna_width'].max() - len(encoded_seq)))\n",
    "X_new = [padded_seq]\n",
    "\n",
    "# Use the trained classifier to predict the class of the new sequence\n",
    "y_new = clf.predict(X_new)\n",
    "print('Predicted class:', y_new[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of each mutation class: [  0.   0. 100.   0.   0.   0.   0.   0.   0.   0.   0.] %\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines (SVMs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.66507177033492 %\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('trainingset.csv')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['spike_aa'], data['variant'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "# You may need to implement custom preprocessing for your specific problem.\n",
    "\n",
    "# Vectorize the amino acid sequences\n",
    "vectorizer = CountVectorizer(analyzer='char', ngram_range=(1, 3))\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# Define the SVM model\n",
    "clf = svm.SVC(kernel='linear', C=1, probability=True)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set labels\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy*100,'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: Other\n"
     ]
    }
   ],
   "source": [
    "# Predict the label of a new sequence\n",
    "new_seq = list(test['spike_aa'])[8]#'MAAFVKVLVTLYLAVAVFVFNAKGEHR'\n",
    "new_seq_vec = vectorizer.transform([new_seq])\n",
    "predicted_label = clf.predict(new_seq_vec)[0]\n",
    "print('Predicted label:', predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes model to classify amino acid sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 51.55795596177815 %\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('trainingset.csv')\n",
    "data =data.drop_duplicates(subset=['spike_aa']).reset_index()\n",
    "data =data[['spike_aa','spike_aa_width', 'variant']]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['spike_aa'], data['variant'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "# You may need to implement custom preprocessing for your specific problem.\n",
    "\n",
    "# Vectorize the amino acid sequences\n",
    "vectorizer = CountVectorizer(analyzer='char', ngram_range=(1,1))\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# Define the Naive Bayes model\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set labels\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy*100,'%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('new_for_model_testing.csv')\n",
    "\n",
    "\n",
    "#test= list(test['spike_aa'])[4]#for predicting \n",
    "#test#\n",
    "#test= test['spike_aa']\n",
    "#modelling_set = pd.read_csv('modelling_set1.csv')#for trainingset\n",
    "modelling_set = pd.read_csv('trainingset.csv')\n",
    "modelling_set =modelling_set.drop_duplicates(subset=['spike_aa']).reset_index()\n",
    "modelling_set =modelling_set[['spike_aa','spike_aa_width', 'variant']]\n",
    "#Using spike\n",
    "sequence=list(modelling_set['spike_aa'])#feature column\n",
    "label=list(modelling_set['variant'])#variants as labels\n",
    "\n",
    "#\n",
    "#Using orf1a\n",
    "#sequence=list(modelling_set['orf1a_aa'])#feature column\n",
    "#label=list(modelling_set['variant'])#variants as labels\n",
    "\n",
    "#modelling_set = modelling_set.drop_duplicates(subset=['spike_aa']).reset_index()\n",
    "#modelling_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Amino acid\n",
    "amino_acids = 'ACDEFGHIKLMNPQRSTVWY*'\n",
    "\n",
    "X = np.array(sequence)\n",
    "y = label\n",
    "\n",
    "# Convert amino acid sequences to numerical vectors\n",
    "aa_to_index = {aa: i for i, aa in enumerate(amino_acids)}\n",
    "X_encoded = []\n",
    "for i in range(len(sequence)):\n",
    "    encoded_seq = [aa_to_index[aa] for aa in X[i]]\n",
    "    padded_seq = np.pad(encoded_seq, (0, modelling_set['spike_aa_width'].max() - len(encoded_seq)))\n",
    "    X_encoded.append(padded_seq)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Random Forest Classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', acc*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "\n",
    "# About the data\n",
    "num_samples = len(modelling_set)\n",
    "sequence_length = modelling_set['spike_aa_width'].max()\n",
    "num_classes = 11\n",
    "amino_acids = 'ACDEFGHIKLMNPQRSTVWY*'\n",
    "\n",
    "#data. Amino acid and its labels(variant)\n",
    "X = np.array(sequence)\n",
    "y = label\n",
    "\n",
    "# Convert amino acid sequences to one-hot encoding\n",
    "aa_to_index = {aa: i for i, aa in enumerate(amino_acids)}\n",
    "X_one_hot = np.zeros((num_samples, sequence_length, len(amino_acids)))\n",
    "for i in range(num_samples):\n",
    "    for j in range(sequence_length):\n",
    "        aa_index = aa_to_index[X[i][j]]\n",
    "        X_one_hot[i][j][aa_index] = 1\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(sequence_length, len(amino_acids))))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_one_hot, y, epochs=10, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network (RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# About the data\n",
    "num_samples = len(modelling_set)\n",
    "sequence_length = modelling_set['spike_aa_width'].max()\n",
    "num_classes = 11\n",
    "amino_acids = 'ACDEFGHIKLMNPQRSTVWY*'\n",
    "\n",
    "#data. Amino acid and its labels(variant)\n",
    "X = np.array(sequence)\n",
    "y = label\n",
    "\n",
    "# Convert amino acid sequences to one-hot encoding\n",
    "aa_to_index = {aa: i for i, aa in enumerate(amino_acids)}\n",
    "X_one_hot = np.zeros((num_samples, sequence_length, len(amino_acids)))\n",
    "for i in range(num_samples):\n",
    "    for j in range(sequence_length):\n",
    "        aa_index = aa_to_index[X[i][j]]\n",
    "        X_one_hot[i][j][aa_index] = 1\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(sequence_length, len(amino_acids))))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_one_hot, y, epochs=10, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion with different classifiers\n",
    "\n",
    "### 1. Random Forest Classifier\n",
    "1. Both the cDNA and Amino acid prediction with spike give >99.5% accuracy\n",
    "2. But the prediction is correctly predicted with Amino acid seqs.\n",
    "3. cDNA seq predctions give all the variants predicted on unseen sequence as 'other'.\n",
    "4. So the better way is to use amino acid sequences for prediction of the variants and probability of getting having new mutations in a sequences consistent to each class (variant).\n",
    "5. Overally, Random Forest gives the best prediction of >99.5%, and predicts correctly with spike amino acids, and can get the probability of getting new mutations.\n",
    "6. Because of large sizes of sequences as string, reducing thenumber by dropping duplicates was helpful to reduce the size of file and time taken to computer and reduces the chances of running out of the memory of the computer.\n",
    "\n",
    "### 2. Support Vector Machines (SVMs)\n",
    "1. Gave an accuracy of 99.67%, and give the correct prediction on the correct sequences (new) \n",
    "2. But if the sequence of is wrong or dammy sequence, then it predicts it as omicron, which is wrong. \n",
    "3. Hence not robust in prediction of new sequences.\n",
    "\n",
    "### 3. Naive Bayes\n",
    "1. Accuracy of 51.6%\n",
    "2. Hence not robust enough.\n",
    "\n",
    "### 4. Neutral Network models\n",
    "1. All the different neutral network models did not compute in my computer the python kernel died\n",
    "2. Possible because of one-hot encoding that needed alot of comptations and increase in dimensionality of that data\n",
    "3. Hence the memory of the computer became limited.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
